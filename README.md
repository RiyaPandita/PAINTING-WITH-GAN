# PAINTING WITH GAN

This project demonstrates how to build and train a Generative Adversarial Network (GAN) for generating images of oil-painted portraits. GANs are a type of unsupervised learning model that learn to capture patterns in data and generate new samples that resemble the original dataset. The dataset used here consists of portraits with varying orientations and poses, making the task challenging but interesting.



## Table of Contents

- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
  - [The Generator](#the-generator)
  - [The Discriminator](#the-discriminator)
- [Training](#training)
- [Results](#results)
- [Conclusion](#conclusion)
- [Resources](#resources)
- [Acknowledgments](#acknowledgments)

---

## Getting Started

### Prerequisites

To run this project, you will need to have the following libraries installed:

-   NumPy
-   Pandas
-   Matplotlib
-   Seaborn
-   TensorFlow
-   Keras
-   PIL (Pillow)

### Installation

1.  **Clone the repository:**
    ```sh
    git clone [https://github.com/your-username/painting-with-gan.git](https://github.com/your-username/painting-with-gan.git)
    cd painting-with-gan
    ```
    (Replace `your-username` with your actual GitHub username.)

2.  **Install the required libraries:**
    It is recommended to create a virtual environment to manage dependencies.
    ```sh
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```
    Then, install the packages:
    ```sh
    pip install numpy pandas matplotlib seaborn tensorflow keras pillow
    ```

---

## Usage

You can use the `painting-with-gan.ipynb` Jupyter Notebook to see the step-by-step process of building and training the GAN.

The notebook is organized into the following sections:

1.  **Importing Libraries**: Imports all the necessary libraries for the project.
2.  **Data Loading & Preprocessing**: Loads the dataset of portrait images and preprocesses them for training. This includes resizing and normalizing the images.
3.  **Building GAN**: Defines the architecture for the Generator and Discriminator models using Keras.
4.  **GAN Compilation**: Compiles the combined GAN model, setting up the optimizers and loss functions.
5.  **Training the Model**: Contains the training loop where the GAN is trained on the portrait dataset over a number of epochs.
6.  **Evaluating the Model**: After training, this section shows how to use the trained generator to create new images and displays the results.
7.  **Conclusion**: A brief summary of the project and the results.

---

## Model Architecture

The Generative Adversarial Network (GAN) consists of two neural networks that are trained simultaneously in a zero-sum game.

### The Generator

The **Generator** model takes a random noise vector (latent sample) as input and attempts to generate a new image that resembles the images in the training dataset. Its architecture typically consists of up-sampling layers like `Conv2DTranspose` to transform the initial noise vector into a full-sized image.

### The Discriminator

The **Discriminator** model is a binary classifier that takes an image as input and tries to predict whether the image is a "real" image from the training dataset or a "fake" image generated by the Generator. Its architecture is a standard convolutional neural network (CNN) designed for image classification.

---

## Training

The training process involves a "cat and mouse" game between the Generator and the Discriminator:

1.  **Train the Discriminator**: The Discriminator is trained on a batch containing both real images from the dataset and fake images from the Generator. It learns to get better at distinguishing between the two.
2.  **Train the Generator**: The Generator is trained to produce images that can "fool" the Discriminator. Its weights are updated based on the Discriminator's output for the generated images. The goal is to make the Discriminator classify the fake images as real.

This cycle is repeated for many epochs. Over time, the Generator learns to produce increasingly realistic and high-quality images.

---

## Results

Here are some examples of images generated by the trained GAN after several epochs of training:

*(You can add your generated images here. For example:)*
![Generated Portrait 1](path/to/your/generated_image_1.png)
![Generated Portrait 2](path/to/your/generated_image_2.png)

---

## Conclusion

This project successfully demonstrates the capability of GANs in generating novel and artistic images. The model was able to learn the features of oil-painted portraits and produce new samples that capture the style and essence of the training data. Further improvements could be made by training for more epochs, using a larger dataset, or tuning the model's architecture and hyperparameters.

---

## Resources

-   [AI Art Blog Post](https://karnikakapoor.blogspot.com/2021/12/ai-art.html)
-   [TensorFlow DCGAN Tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)
-   [Keras DCGAN Example](https://keras.io/examples/generative/dcgan_overriding_train_step/)
-   [How to Train a GAN](https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/)

---

## Acknowledgments

This project is based on the concepts and code presented in the "PAINTING WITH GAN" notebook. A big thank you to the original author for sharing their work.
